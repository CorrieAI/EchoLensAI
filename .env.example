# ============================================================================
# REQUIRED: AI Service Configuration
# ============================================================================
# Get your API keys from:
# - OpenAI: https://platform.openai.com/api-keys
# - Groq: https://console.groq.com/keys (recommended for fast/cheap transcription & chat)

# Recommended setup: Use Groq for chat + transcription, OpenAI for embeddings + TTS
# This gives you the best speed and lowest cost!

# --- CHAT MODEL (for summaries, term extraction, chat responses) ---
# Groq is HIGHLY recommended - it's fast and cheap!
CHAT_API_KEY=your_chat_api_key_here
CHAT_API_BASE=https://api.groq.com/openai/v1
CHAT_MODEL=openai/gpt-oss-120b
CHAT_STREAMING=true
CHAT_TEMPERATURE=0.5
CHAT_MAX_TOKENS=65000

# To use OpenAI instead:
# CHAT_API_KEY=sk-your_openai_key
# CHAT_API_BASE=
# CHAT_MODEL=gpt-4o-mini

# --- EMBEDDING MODEL (for vector search) ---
# Note: Groq doesn't support embeddings - must use OpenAI or Ollama
EMBEDDING_API_KEY=your_embedding_api_key_here
EMBEDDING_API_BASE=
EMBEDDING_MODEL=text-embedding-3-small
# Embedding dimensions - MUST match your model:
#   OpenAI text-embedding-3-small: 1536
#   OpenAI text-embedding-3-large: 3072
#   nomic-embed-text (Ollama): 768
EMBEDDING_DIMENSIONS=1536
#
# ⚠️  WARNING: Changing EMBEDDING_DIMENSIONS after processing episodes requires a full reset!
# If you've already processed episodes and want to switch embedding models:
#   1. Run ./full-reset.sh to delete all data and reset the database
#   2. Update EMBEDDING_DIMENSIONS to match your new model
#   3. Restart the stack and re-add/process your podcasts
# The app will detect dimension mismatches and refuse to start if embeddings exist.

# To use Ollama (local/free):
# EMBEDDING_API_KEY=ollama
# EMBEDDING_API_BASE=http://localhost:11434/v1
# EMBEDDING_MODEL=nomic-embed-text
# EMBEDDING_DIMENSIONS=768

# --- TRANSCRIPTION MODEL (Speech-to-Text / Whisper) ---
# Groq is HIGHLY recommended - fast and cheap!
# Can use same key as CHAT_API_KEY if both are Groq
TRANSCRIPTION_API_KEY=your_transcript_api_key_here
TRANSCRIPTION_API_BASE=https://api.groq.com/openai/v1
TRANSCRIPTION_MODEL=whisper-large-v3-turbo

# To use OpenAI instead:
# TRANSCRIPTION_API_KEY=sk-your_openai_key
# TRANSCRIPTION_API_BASE=
# TRANSCRIPTION_MODEL=whisper-1

# Keep audio chunks after transcription (for debugging)
# Default: false (chunks are automatically deleted to save disk space)
# Set to true if you want to keep chunks for inspection/debugging
KEEP_AUDIO_CHUNKS=false

# --- TEXT-TO-SPEECH (Optional - generates audio summaries) ---
# OpenAI, Elevenlabs or DeepGram (Groq's TTS is sub-par currently)
# Set TTS_ENABLED=false to disable audio summary generation
TTS_API_KEY=your_tts_api_key_here
TTS_API_BASE=
TTS_MODEL=tts-1
# Voices: alloy, echo, fable, onyx, nova, shimmer
TTS_VOICE=alloy
TTS_ENABLED=false

# ============================================================================
# SECURITY: Development & Production Passwords
# ============================================================================
# Development mode: Simple passwords for local development
# Production mode: Set strong passwords before deploying!

# Development credentials (used by docker-compose.dev.yaml)
POSTGRES_PASSWORD_DEV=echolens_dev
REDIS_PASSWORD_DEV=echolens_dev

# Production credentials (used by docker-compose.yaml)
# CHANGE THESE before deploying to production!
POSTGRES_PASSWORD=change_this_in_production
REDIS_PASSWORD=change_this_in_production

# ============================================================================
# OPTIONAL: Advanced Settings (defaults work for most users)
# ============================================================================

# --- Database Configuration ---
# Leave as default for Docker setup
# Only change if connecting to external database (Neon, AWS RDS, etc.)

# For Docker development (default):
DATABASE_URL=postgresql+asyncpg://echolens:${POSTGRES_PASSWORD_DEV}@localhost:5432/echolens

# For external database (uncomment and edit):
# DATABASE_URL=postgresql+asyncpg://user:password@your-host:5432/dbname

# --- Celery & Redis Configuration ---
# Leave as default for Docker setup
CELERY_BROKER_URL=redis://:${REDIS_PASSWORD_DEV}@localhost:6379/0
CELERY_RESULT_BACKEND=redis://:${REDIS_PASSWORD_DEV}@localhost:6379/0

# Number of concurrent worker processes (2-4 recommended)
CELERY_WORKER_CONCURRENCY=2

# --- Application Settings ---
# Timezone for display/logging (database always uses UTC)
# Examples: America/New_York, America/Los_Angeles, UTC, Europe/London
TIMEZONE=UTC

# --- Port Configuration ---
# Host ports for Docker services (change if you have port conflicts)
# Internal container ports remain the same, these are the ports exposed to your host machine
FRONTEND_PORT=3000
BACKEND_PORT=8000
POSTGRES_PORT=5432
REDIS_PORT=6379
ADMINER_PORT=8080

# CORS - Frontend URLs allowed to access the API
# IMPORTANT: If you change FRONTEND_PORT above, you must update this to match!
# For production, replace with your actual domain(s)
CORS_ORIGINS=http://localhost:3000

# File Storage
UPLOAD_DIR=./echolens_data/uploads
MAX_UPLOAD_SIZE=524288000

# ============================================================================
# Alternative Configuration Examples
# ============================================================================

# Example 1: All OpenAI (simpler but more expensive)
# CHAT_API_KEY=sk-your_openai_key
# CHAT_API_BASE=
# CHAT_MODEL=gpt-4o-mini
# EMBEDDING_API_KEY=sk-your_openai_key
# TRANSCRIPTION_API_KEY=sk-your_openai_key
# TRANSCRIPTION_API_BASE=
# TRANSCRIPTION_MODEL=whisper-1
# TTS_API_KEY=sk-your_openai_key

# Example 2: Groq for chat + transcription, OpenAI for embeddings + TTS (Recommended - DEFAULT)
# CHAT_API_KEY=gsk_your_groq_key
# EMBEDDING_API_KEY=sk-your_openai_key
# TRANSCRIPTION_API_KEY=gsk_your_groq_key
# TTS_API_KEY=sk-your_openai_key

# Example 3: Mix Ollama (local/free) with OpenAI
# CHAT_API_KEY=ollama
# CHAT_API_BASE=http://localhost:11434/v1
# CHAT_MODEL=llama3.1
# EMBEDDING_API_KEY=ollama
# EMBEDDING_API_BASE=http://localhost:11434/v1
# EMBEDDING_MODEL=nomic-embed-text
# EMBEDDING_DIMENSIONS=768
# TRANSCRIPTION_API_KEY=sk-your_openai_key
# TRANSCRIPTION_API_BASE=
# TTS_API_KEY=sk-your_openai_key
